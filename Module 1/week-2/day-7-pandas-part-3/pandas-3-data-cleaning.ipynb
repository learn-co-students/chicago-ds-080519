{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Goals:\n",
    "\n",
    "- practice cleaning a real dataset\n",
    "- practice using `py` files and the terminal in conjunction with jupyter notebooks\n",
    "- run a `py` script through the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "As data scientists, we want to build a model to predict the sale price of a house in Seattle in 2019, based on its square footage. We know that the King County Department of Assessments has comprehensive data available on real property sales in the Seattle area. We need to prepare the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, get the data!\n",
    "\n",
    "When working on a project involving data that can fit on our computer, we store it in a `data` directory.\n",
    "\n",
    "```bash\n",
    "cd <project_directory>  # example: cd ~/flatiron_ds/pandas-3\n",
    "mkdir data\n",
    "cd data\n",
    "```\n",
    "\n",
    "Note that `<project_directory>` in angle brackets is a _placeholder_. You should type the path to the actual location on your computer where you're working on this project. Do not literally type `<project_directory>` and _do not type the angle brackets_. You can see an example in the _comment_ to the right of the command above.\n",
    "\n",
    "![terminal](https://media3.giphy.com/media/yR4xZagT71AAM/giphy.gif?cid=790b76115d3620444553533759086a54&rid=giphy.gif)\n",
    "\n",
    "Now, we'll need to download the two data files that we need. We can do this at the command line:\n",
    "\n",
    "```bash\n",
    "wget https://aqua.kingcounty.gov/extranet/assessor/Real%20Property%20Sales.zip\n",
    "wget https://aqua.kingcounty.gov/extranet/assessor/Residential%20Building.zip\n",
    "```\n",
    "\n",
    "*Note:* If you do not have the `wget` command yet, you can install it with `brew install wget`, or use `curl <url> -o <filename>`.\n",
    "\n",
    "Note that `%20` in a URL translates into a space. Even though you will *never put spaces in filenames*, you may need to deal with spaces that _other_ people have used in filenames.\n",
    "\n",
    "There are two ways to handle the spaces in these filenames when referencing them at the command line.\n",
    "![internetgif](https://media2.giphy.com/media/QWkuGmMgphvmE/giphy.gif?cid=790b76115d361f42304a6850369f37ea&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. You can _escape_ the spaces by putting a backslash (`\\`, remember _backslash is next to backspace_) before each one:\n",
    "\n",
    "`unzip Real\\ Property\\ Sales.zip`\n",
    "\n",
    "This is what happens if you tab-complete the filename in the terminal. Tab completion is your friend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. You can put the entire filename in quotes:\n",
    "\n",
    "`unzip \"Real Property Sales.zip\"`\n",
    "\n",
    "Try unzipping these files with the `unzip` command. The `unzip` command takes one argument, the name of the file that you want to unzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('data/Real Property Sales.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing pink? Warnings are useful!\n",
    "\n",
    "Note the warning above: `DtypeWarning: Columns (1, 2) have mixed types.` Because we start with an index of zero, the columns that we're being warned about are actually the _second_ and _third_ columns, `sales_df['Major']` and `sales_df['Minor']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overload?\n",
    "\n",
    "That's a lot of columns. We're only interested in identifying the date, sale price, and square footage of each specific property. What can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df[['Major', 'Minor', 'DocumentDate', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df = pd.read_csv('data/Residential Building.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another warning! Which column has index 11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_df.columns[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ZipCode` seems like a potentially useful column. We'll need it to determine which house sales took place in Seattle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So many features!\n",
    "\n",
    "As data scientists, we should be _very_ cautious about discarding potentially useful data. But, today, we're interested in _only_ the total square footage of each property. What can we do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_df = bldg_df[['Major', 'Minor', 'SqFtTotLiving', 'ZipCode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.merge(sales_df, bldg_df, on=['Major', 'Minor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error!\n",
    "\n",
    "Why are we seeing an error when we try to join the dataframes?\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 2013160 entries, 0 to 2013159\n",
    "Data columns (total 4 columns):\n",
    "Major           object\n",
    "Minor           object\n",
    "DocumentDate    object\n",
    "SalePrice       int64\n",
    "dtypes: int64(1), object(3)\n",
    "memory usage: 61.4+ MB</pre></td>\n",
    "        <td style=\"text-align:left\"><pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 511359 entries, 0 to 511358\n",
    "Data columns (total 4 columns):\n",
    "Major            511359 non-null int64\n",
    "Minor            511359 non-null int64\n",
    "SqFtTotLiving    511359 non-null int64\n",
    "ZipCode          468345 non-null object\n",
    "dtypes: int64(3), object(1)\n",
    "memory usage: 15.6+ MB\n",
    "</pre></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Review the error message in light of the above:\n",
    "\n",
    "* `ValueError: You are trying to merge on object and int64 columns.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Major'] = pd.to_numeric(sales_df['Major'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error!\n",
    "\n",
    "Note the useful error message above:\n",
    "\n",
    "`ValueError: Unable to parse string \"      \" at position 936643`\n",
    "\n",
    "In this case, we want to treat non-numeric values as missing values. Let's see if there's a way to change how the `pd.to_numeric` function handles errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The single question mark means \"show me the docstring\"\n",
    "pd.to_numeric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the part that we're looking for:\n",
    "```\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If 'raise', then invalid parsing will raise an exception\n",
    "    - If 'coerce', then invalid parsing will be set as NaN\n",
    "    - If 'ignore', then invalid parsing will return the input\n",
    "```\n",
    "\n",
    "Let's try setting the `errors` parameter to `'coerce'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Major'] = pd.to_numeric(sales_df['Major'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Let's do the same thing with the `Minor` parcel number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Minor'] = pd.to_numeric(sales_df['Minor'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try our join again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.merge(sales_df, bldg_df, on=['Major', 'Minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see right away that we're missing zip codes for many of the sales transactions. (1321536 non-null entries for ZipCode is fewer than the 1436772 entries in the dataframe.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.loc[sales_data['ZipCode'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are interested in finding houses in Seattle zip codes, we will need to drop the rows with missing zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = sales_data.loc[~sales_data['ZipCode'].isna(), :]\n",
    "\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn: Data Cleaning with Pandas\n",
    "![turtletype](https://media3.giphy.com/media/cFdHXXm5GhJsc/giphy.gif?cid=790b76115d3627d8354c7179366b0672&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Investigate and drop rows with invalid values in the SalePrice and SqFtTotLiving columns.\n",
    "\n",
    "Use multiple notebook cells to accomplish this! Press `[esc]` then `B` to create a new cell below the current cell. Press `[return]` to start typing in the new cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Investigate and handle non-numeric ZipCode values\n",
    "\n",
    "Can you find a way to shorten ZIP+4 codes to the first five digits?\n",
    "\n",
    "What's the right thing to do with missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the error message and decide how to fix it.\n",
    "# Note: using errors='coerce' is the *wrong* choice in this case.\n",
    "def is_integer(x):\n",
    "    try:\n",
    "        _ = int(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "sales_data.loc[sales_data['ZipCode'].apply(is_integer) == False, 'ZipCode'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add a column for PricePerSqFt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Subset the data to 2019 sales only.\n",
    "\n",
    "We can assume that the DocumentDate is approximately the sale date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Subset the data to zip codes within the City of Seattle.\n",
    "\n",
    "You'll need to find a list of Seattle zip codes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is the mean price per square foot for a house sold in Seattle in 2019?\n",
    "\n",
    "Don't just type the answer. Type code that generates the answer as output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning code into a script\n",
    "\n",
    "#### make a new .py file\n",
    "- open a new `.py` file _or_ open a new jupyter notbook and export as a `.py` file so we can start to edit the `.py` file directly\n",
    "- save the file as `mean_ppsf_seattle.py`\n",
    "- look at all your code between `sales_df = pd.read_csv('data/Real Property Sales.zip')` and question `number 6` above\n",
    "\n",
    "#### review & organize your code\n",
    "- _organize_ your code in the `mean_ppsf_seattle.py` to start with `sales_df = pd.read_csv('data/Real Property Sales.zip')` and end with printing out the mean price per square foot for a house sold in seattle in 2019\n",
    "- the code should be able to run without throwing any errors\n",
    "- remember to include `import pandas as pd` and any other necessary statements at the start of your script\n",
    "\n",
    "#### test your script\n",
    "- go to the terminal\n",
    "- make sure you are in the same directory path as your jupyter notebook and the `.py` file\n",
    "- in the terminal type and then run `python mean_ppsf_seattle.py`\n",
    "- confirm the script returns in terminal what you wanted it to return\n",
    "\n",
    "#### send your script to Ammar and Marisa\n",
    "\n",
    "![anykey](https://media2.giphy.com/media/26BGIqWh2R1fi6JDa/giphy.gif?cid=790b76115d3627d8354c7179366b0672&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
